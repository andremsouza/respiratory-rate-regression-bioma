{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Iteration Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Python environment with Anaconda.\n",
    "\n",
    "To create a conda environment from an environment.yml file, you can use the following bash command:\n",
    "\n",
    "```bash\n",
    "conda env create -f environment.yml\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup .env file\n",
    "\n",
    "It is necessary to setup a .dotenv file for connection with Label Studio and Docker. The .env file must have the following keys:\n",
    "\n",
    "```bash\n",
    "# Label Studio environment variables for API\n",
    "LABEL_STUDIO_URL=foo\n",
    "LABEL_STUDIO_API_KEY=foo\n",
    "LABEL_STUDIO_CONTAINER_ID=foo\n",
    "LABEL_STUDIO_CONTAINER_DATA_DIR=fo\n",
    "LABEL_STUDIO_DOWNLOAD_DIR=fo\n",
    "LABEL_STUDIO_PROJECT_ID=foo\n",
    "```\n",
    "\n",
    "- `LABEL_STUDIO_URL`: The URL of the Label Studio instance for API communication. Example: \"localhost:8000\"\n",
    "- `LABEL_STUDIO_API_KEY`: The API key used for authentication with the Label Studio instance.\n",
    "- `LABEL_STUDIO_CONTAINER_ID`: The ID of the Docker container used by Label Studio.\n",
    "- `LABEL_STUDIO_CONTAINER_DATA_DIR`: The directory path where the container stores data. Example: \"/label-studio/data/media/upload/\"\n",
    "- `LABEL_STUDIO_DOWNLOAD_DIR`: The directory path where downloaded files are stored. Example: \"./data/lsvideos/\"\n",
    "- `LABEL_STUDIO_PROJECT_ID`: The ID of the project in Label Studio. Example: \"6\"\n",
    "\n",
    "These keys are used to configure the connection and interaction between the interpreter and the Label Studio instance for recovering and loading data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing to repository's root directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import dotenv\n",
    "\n",
    "os.chdir(os.getcwd().split(\"test\")[0])\n",
    "print(f\"cwd: {os.getcwd()}\")\n",
    "dotenv.load_dotenv()\n",
    "sys.path.append(os.getenv(\"PACKAGEPATH\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.getenv(\"HOME\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from datetime import datetime\n",
    "from functools import partial\n",
    "import os\n",
    "import random\n",
    "\n",
    "import dotenv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models.video import R2Plus1D_18_Weights\n",
    "from torchvision.transforms.v2 import Compose, InterpolationMode, Normalize, Resize\n",
    "from torchvision.io import write_video\n",
    "from torchvision.transforms._presets import VideoClassification\n",
    "from tqdm import tqdm\n",
    "\n",
    "import config\n",
    "from datasets import VideoDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants and arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from .dotenv\n",
    "dotenv.load_dotenv(dotenv_path=\".env\", verbose=True, override=True)\n",
    "# Set torch precision\n",
    "torch.set_float32_matmul_precision(\"high\")\n",
    "# Set constants\n",
    "# Set argument constants\n",
    "LABEL_STUDIO_URL: str = os.getenv(\"LABEL_STUDIO_URL\")\n",
    "LABEL_STUDIO_API_KEY: str = os.getenv(\"LABEL_STUDIO_API_KEY\")\n",
    "LABEL_STUDIO_CONTAINER_ID: str = os.getenv(\"LABEL_STUDIO_CONTAINER_ID\")\n",
    "LABEL_STUDIO_CONTAINER_DATA_DIR: str = os.getenv(\"LABEL_STUDIO_CONTAINER_DATA_DIR\")\n",
    "LABEL_STUDIO_DOWNLOAD_DIR: str = os.getenv(\"LABEL_STUDIO_DOWNLOAD_DIR\")\n",
    "LABEL_STUDIO_PROJECT_ID: str = os.getenv(\"LABEL_STUDIO_PROJECT_ID\")\n",
    "TARGET_FPS: float = 5.0\n",
    "SAMPLE_SIZE: int = 16\n",
    "HOP_LENGTH: int = 8\n",
    "FILTER_TASK_IDS: list | None = None\n",
    "BBOX_TRANSFORM: bool = False\n",
    "BBOX_TRANSFORM_CORNERS: bool = False\n",
    "DOWNLOAD_VIDEOS: bool = True\n",
    "DOWNLOAD_VIDEOS_OVERWRITE: bool = False\n",
    "VERBOSE: bool = True\n",
    "MODEL_DIR: str = \"models/\"\n",
    "LOG_DIR: str = \"logs/\"\n",
    "NUM_WORKERS: int = 1\n",
    "BATCH_SIZE: int = 16\n",
    "OPTIMIZER: str = \"adamw\"\n",
    "LEARNING_RATE: float = 0.001\n",
    "WEIGHT_DECAY: float = 0.01\n",
    "MAX_EPOCHS: int = 1000\n",
    "PATIENCE: int = 8\n",
    "SEED: int = 42\n",
    "MODEL_NAME: str = \"r2plus1d18\" + \"_regression\"\n",
    "PRETRAINED: bool = True\n",
    "# Set random seed\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important: Change bounding box parameter values to change data loading methodology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BBOX_TRANSFORM: bool = True # ! Adjust this variable\n",
    "BBOX_TRANSFORM_CORNERS: bool = True # ! Adjust this variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directories if they don't exist\n",
    "if not os.path.exists(LABEL_STUDIO_DOWNLOAD_DIR):\n",
    "    os.makedirs(LABEL_STUDIO_DOWNLOAD_DIR, exist_ok=True)\n",
    "if not os.path.exists(\n",
    "    LOG_DIR,\n",
    "):\n",
    "    os.makedirs(LOG_DIR, exist_ok=True)\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.makedirs(MODEL_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset and dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get transforms from weights\n",
    "if BBOX_TRANSFORM:\n",
    "    # Use r2plus1d18 transforms, without center crop\n",
    "    transform = partial(\n",
    "        VideoClassification, crop_size=(112, 112), resize_size=(112, 112)\n",
    "    )()\n",
    "else:\n",
    "    # Use r2plus1d18 default transforms\n",
    "    transform = R2Plus1D_18_Weights.DEFAULT.transforms()\n",
    "print(f\"[{datetime.now()}]: Loading datasets\")\n",
    "# Load dataset\n",
    "dataset = VideoDataset(\n",
    "    url=LABEL_STUDIO_URL,\n",
    "    api_key=LABEL_STUDIO_API_KEY,\n",
    "    project_id=int(LABEL_STUDIO_PROJECT_ID),\n",
    "    data_dir=LABEL_STUDIO_DOWNLOAD_DIR,\n",
    "    container_id=LABEL_STUDIO_CONTAINER_ID,\n",
    "    container_data_dir=LABEL_STUDIO_CONTAINER_DATA_DIR,\n",
    "    fps=TARGET_FPS,\n",
    "    sample_size=SAMPLE_SIZE,\n",
    "    hop_length=HOP_LENGTH,\n",
    "    filter_task_ids=FILTER_TASK_IDS,\n",
    "    bbox_transform=BBOX_TRANSFORM,\n",
    "    bbox_transform_corners=BBOX_TRANSFORM_CORNERS,\n",
    "    download_videos=DOWNLOAD_VIDEOS,\n",
    "    download_videos_overwrite=DOWNLOAD_VIDEOS_OVERWRITE,\n",
    "    classification=False,\n",
    "    prune_invalid=False,\n",
    "    transform=transform,\n",
    "    target_transform=lambda x: torch.tensor(x).unsqueeze(0),\n",
    "    verbose=VERBOSE,\n",
    ")\n",
    "# Get task ids\n",
    "task_ids = dataset.annotations[\"id\"].unique()\n",
    "# Split task ids into train and test\n",
    "train_task_ids, test_task_ids = train_test_split(\n",
    "    task_ids, test_size=0.2, random_state=SEED\n",
    ")\n",
    "# Split dataset into train and test\n",
    "# del dataset\n",
    "train_dataset = VideoDataset(\n",
    "    url=LABEL_STUDIO_URL,\n",
    "    api_key=LABEL_STUDIO_API_KEY,\n",
    "    project_id=int(LABEL_STUDIO_PROJECT_ID),\n",
    "    data_dir=LABEL_STUDIO_DOWNLOAD_DIR,\n",
    "    container_id=LABEL_STUDIO_CONTAINER_ID,\n",
    "    container_data_dir=LABEL_STUDIO_CONTAINER_DATA_DIR,\n",
    "    fps=TARGET_FPS,\n",
    "    sample_size=SAMPLE_SIZE,\n",
    "    hop_length=HOP_LENGTH,\n",
    "    filter_task_ids=train_task_ids,\n",
    "    bbox_transform=BBOX_TRANSFORM,\n",
    "    bbox_transform_corners=BBOX_TRANSFORM_CORNERS,\n",
    "    download_videos=DOWNLOAD_VIDEOS,\n",
    "    download_videos_overwrite=DOWNLOAD_VIDEOS_OVERWRITE,\n",
    "    classification=False,\n",
    "    prune_invalid=True,\n",
    "    transform=transform,\n",
    "    target_transform=lambda x: torch.tensor(x).unsqueeze(0),\n",
    "    verbose=VERBOSE,\n",
    ")\n",
    "test_dataset = VideoDataset(\n",
    "    url=LABEL_STUDIO_URL,\n",
    "    api_key=LABEL_STUDIO_API_KEY,\n",
    "    project_id=int(LABEL_STUDIO_PROJECT_ID),\n",
    "    data_dir=LABEL_STUDIO_DOWNLOAD_DIR,\n",
    "    container_id=LABEL_STUDIO_CONTAINER_ID,\n",
    "    container_data_dir=LABEL_STUDIO_CONTAINER_DATA_DIR,\n",
    "    fps=TARGET_FPS,\n",
    "    sample_size=SAMPLE_SIZE,\n",
    "    hop_length=HOP_LENGTH,\n",
    "    filter_task_ids=test_task_ids,\n",
    "    bbox_transform=BBOX_TRANSFORM,\n",
    "    bbox_transform_corners=BBOX_TRANSFORM_CORNERS,\n",
    "    download_videos=DOWNLOAD_VIDEOS,\n",
    "    download_videos_overwrite=DOWNLOAD_VIDEOS_OVERWRITE,\n",
    "    classification=False,\n",
    "    prune_invalid=True,\n",
    "    transform=transform,\n",
    "    target_transform=lambda x: torch.tensor(x).unsqueeze(0),\n",
    "    verbose=VERBOSE,\n",
    ")\n",
    "print(f\"[{datetime.now()}]: Loaded datasets\")\n",
    "# Create dataloaders\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=True,\n",
    ")\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=True,\n",
    ")\n",
    "print(f\"[{datetime.now()}]: Created data loaders\")\n",
    "# Create model\n",
    "# Set dataloaders (for generic use)\n",
    "train_dataloaders: list[DataLoader] = [train_dataloader]\n",
    "test_dataloaders: list[DataLoader] = [test_dataloader]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset iteration methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get a sample from the dataset and save it to .mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a sample from the dataset and save it\n",
    "train_dataset.transform = None\n",
    "sample, _ = train_dataset[0]\n",
    "print(f\"[{datetime.now()}]: Got sample\")\n",
    "# Save sample as video\n",
    "write_video(\n",
    "    os.path.join(\"sample.mp4\"),\n",
    "    # sample.permute(1, 2, 3, 0),\n",
    "    sample.permute(0, 2, 3, 1),\n",
    "    fps=TARGET_FPS,\n",
    ")\n",
    "print(f\"[{datetime.now()}]: Saved sample as video {os.path.join('sample.mp4')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterate through dataset and save samples to output folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder: str = \"data/output\"\n",
    "# Create directories if they don't exist\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "for idx, (sample, target) in enumerate(tqdm(dataset)):\n",
    "    task_id = dataset.samples.iloc[idx].task_id\n",
    "    segment_id = dataset.samples.iloc[idx].segment_id\n",
    "    sample_id = dataset.samples.iloc[idx].sample_id\n",
    "    write_video(\n",
    "        os.path.join(output_folder, f\"{task_id}_{segment_id}_{sample_id}.mp4\"),\n",
    "        # [C, T, H, W] -> [T, H, W, C]\n",
    "        sample.permute(1, 2, 3, 0),\n",
    "        # sample.permute(0, 2, 3, 1),\n",
    "        fps=TARGET_FPS,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterate through entire dataloaders to test functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through train and test datasets with dataloaders\n",
    "break_early: bool = True\n",
    "for train_dataloader, test_dataloader in zip(train_dataloaders, test_dataloaders):\n",
    "    print(f\"[{datetime.now()}]: Got dataloaders\")\n",
    "    # Iterate through samples in dataloader\n",
    "    print(f\"[{datetime.now()}]: Iterating through train dataloader\")\n",
    "    for i, (x, y) in enumerate(train_dataloader):\n",
    "        print(f\"[{datetime.now()}]: Got batch {i}\")\n",
    "        # Print shapes\n",
    "        print(f\"x.shape: {x.shape}\")\n",
    "        print(f\"y.shape: {y.shape}\")\n",
    "        if break_early:\n",
    "            break\n",
    "    print(f\"[{datetime.now()}]: Finished iterating through train dataloader\")\n",
    "    print(f\"[{datetime.now()}]: Iterating through test dataloader\")\n",
    "    for i, (x, y) in enumerate(test_dataloader):\n",
    "        print(f\"[{datetime.now()}]: Got batch {i}\")\n",
    "        # Print shapes\n",
    "        print(f\"x.shape: {x.shape}\")\n",
    "        print(f\"y.shape: {y.shape}\")\n",
    "        if break_early:\n",
    "            break\n",
    "    print(f\"[{datetime.now()}]: Finished iterating through test dataloader\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
